{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "Copyright 2019 Navdeep Gill, Patrick Hall, Kim Montgomery, Nick Schmidt\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**DISCLAIMER**: This notebook is not legal compliance advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the training and test data\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Specify data and output directories\n",
    "main ='~/article-information-2019/data/output/'\n",
    "\n",
    "# Specify filenames\n",
    "train_filename = 'hmda_train.csv'\n",
    "test_filename = 'hmda_test.csv'\n",
    "\n",
    "# Load data\n",
    "TRAIN = pd.read_csv(main + train_filename)\n",
    "TEST = pd.read_csv(main + test_filename)\n",
    "\n",
    "\n",
    "training_columns = list(TRAIN.columns)\n",
    "target_column = 'high_priced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change debt_to_income_ratio to an integer\n",
    "\n",
    "import numpy as np\n",
    "import statistics \n",
    "\n",
    "def transform_debt_to_income_ratio(x):\n",
    "    answer = x\n",
    "    if x=='30%-<36%':\n",
    "        answer = 33   \n",
    "    elif x=='20%-<30%':   \n",
    "        answer = 25\n",
    "    elif x=='50%-60%': \n",
    "        answer = 55\n",
    "    elif x=='<20%': \n",
    "        answer = 10\n",
    "    elif x=='>60%': \n",
    "        answer = 80\n",
    "    else:\n",
    "        try:\n",
    "            x_int = int(x)\n",
    "            answer = x_int\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return answer\n",
    "\n",
    "def isnan(x):\n",
    "    return np.isnan(x)\n",
    "        \n",
    "def replace_nan(x, med):\n",
    "    answer = x\n",
    "    if np.isnan(x):\n",
    "        answer = med\n",
    "    return answer\n",
    "\n",
    "# Change the debt to income ratio to a float column\n",
    "TRAIN[\"debt_to_income_ratio\"] = TRAIN[\"debt_to_income_ratio\"].apply(transform_debt_to_income_ratio)\n",
    "TEST[\"debt_to_income_ratio\"] = TEST[\"debt_to_income_ratio\"].apply(transform_debt_to_income_ratio)\n",
    "\n",
    "# Create a flag for missing values\n",
    "median = statistics.median(TRAIN[\"debt_to_income_ratio\"])\n",
    "TRAIN[\"debt_to_income_ratio_missing\"] = TRAIN[\"debt_to_income_ratio\"].apply(isnan)\n",
    "TEST[\"debt_to_income_ratio_missing\"] = TEST[\"debt_to_income_ratio\"].apply(isnan)\n",
    "\n",
    "# Replace missing with median\n",
    "TRAIN[\"debt_to_income_ratio\"] = TRAIN[\"debt_to_income_ratio\"].apply(lambda x: replace_nan(x, median))\n",
    "TEST[\"debt_to_income_ratio\"] = TEST[\"debt_to_income_ratio\"].apply(lambda x: replace_nan(x, median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loan to value ratio based on the other features\n",
    "\n",
    "TRAIN[\"loan_to_value_ratio\"] = TRAIN[\"loan_amount\"] / TRAIN[\"property_value\"] \n",
    "TEST[\"loan_to_value_ratio\"] = TEST[\"loan_amount\"] / TEST[\"property_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize some of the features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = [\"loan_amount\", \"loan_to_value_ratio\", \"no_intro_rate_period\"]\n",
    "features += [\"intro_rate_period\", \"property_value\", \"income\"]\n",
    "features += [\"debt_to_income_ratio\"] \n",
    "            \n",
    "            \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(TRAIN[features])\n",
    "std_features_TRAIN = pd.DataFrame(scaler.transform(TRAIN[features]), columns=[item + \"_std\" for item in features])\n",
    "std_features_TEST = pd.DataFrame(scaler.transform(TEST[features]), columns=[item + \"_std\" for item in features])\n",
    "\n",
    "TRAIN = pd.concat([TRAIN, std_features_TRAIN], axis=1)\n",
    "TEST = pd.concat([TEST, std_features_TEST], axis=1)\n",
    "\n",
    "TRAIN = TRAIN.drop(features, axis=1)\n",
    "TEST = TEST.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transformed datasets\n",
    "\n",
    "TRAIN.to_csv(main+'hmda_train_processed.csv', index=False)\n",
    "TEST.to_csv(main+'hmda_test_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
