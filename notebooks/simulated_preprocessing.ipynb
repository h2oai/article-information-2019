{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "Copyright 2019 Navdeep Gill, Patrick Hall, Kim Montgomery, Nick Schmidt\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**DISCLAIMER**: This notebook is not legal compliance advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the training and test data\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Specify data and output directories\n",
    "main ='~/article-information-2019/data/output/'\n",
    "\n",
    "# Specify filenames\n",
    "train_filename = 'simu_train.csv'\n",
    "test_filename = 'simu_test.csv'\n",
    "\n",
    "# Load data\n",
    "TRAIN = pd.read_csv(main + train_filename)\n",
    "TEST = pd.read_csv(main + test_filename)\n",
    "\n",
    "training_columns = list(TRAIN.columns)\n",
    "target_column = 'outcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat1\n"
     ]
    }
   ],
   "source": [
    "# One hot encode selected columns\n",
    "\n",
    "one_hot = ['cat1']\n",
    "\n",
    "for oh_column in one_hot:\n",
    "    print(oh_column)\n",
    "    train_len = len(TRAIN)\n",
    "    DATA = pd.concat([TRAIN, TEST], axis=0).reindex()\n",
    "    \n",
    "    oh_transformed_column = pd.get_dummies(DATA[oh_column])\n",
    "    oh_transformed_column.columns = [oh_column + '_' + str(item) for item in list(oh_transformed_column.columns)]\n",
    "    DATA = DATA.drop(oh_column, axis=1)\n",
    "    DATA= pd.concat([DATA,oh_transformed_column], axis=1)\n",
    "    TRAIN = DATA.iloc[0:train_len, :].reindex()\n",
    "    TEST = DATA.iloc[train_len:, :].reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize some of the features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['fried1', 'fried2', 'fried3', 'fried4', 'fried5']\n",
    "                     \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(TRAIN[features])\n",
    "std_features_TRAIN = pd.DataFrame(scaler.transform(TRAIN[features]), columns=[item + \"_std\" for item in features])\n",
    "std_features_TEST = pd.DataFrame(scaler.transform(TEST[features]), columns=[item + \"_std\" for item in features])\n",
    "\n",
    "TRAIN = pd.concat([TRAIN, std_features_TRAIN], axis=1)\n",
    "TEST = pd.concat([TEST, std_features_TEST], axis=1)\n",
    "\n",
    "TRAIN = TRAIN.drop(features, axis=1)\n",
    "TEST = TEST.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transformed datasets\n",
    "\n",
    "TRAIN.to_csv(main+'train_simulated_processed.csv', index=False)\n",
    "TEST.to_csv(main+'test_simulated_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "information-article",
   "language": "python",
   "name": "information-article"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
